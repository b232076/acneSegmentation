# SegmentaÃ§Ã£o de Espinhas em Faces com U-Net

Este projeto tem como objetivo realizar a **segmentaÃ§Ã£o automÃ¡tica de espinhas** em imagens faciais, utilizando redes neurais convolucionais (CNNs) e tÃ©cnicas de visÃ£o computacional.



## âœï¸  DescriÃ§Ã£o do Problema

A identificaÃ§Ã£o de espinhas em imagens de rosto humano Ã© desafiadora devido ao tamanho da regiÃ£o de cada imagem, variaÃ§Ã£o de iluminaÃ§Ã£o, tons de pele e presenÃ§a de ruÃ­dos. Este trabalho visa detectar **regiÃµes com espinhas** a partir de imagens de resoluÃ§Ã£o convencional (smartphones), utilizando **mÃ¡scaras binÃ¡rias** geradas manualmente como referÃªncia para o treinamento.

O modelo utilizado foi uma U-Net personalizada, com ajustes para capturar **estruturas pequenas e sutis da pele**.

---

## âš™ï¸ InstalaÃ§Ã£o

Clone o repositÃ³rio e instale as dependÃªncias:

```bash
git clone https://github.com/seu-usuario/seu-repositorio.git
cd seu-repositorio
pip install -r requirements.txt
```

Certifique-se de ter Python 3.8+ e uma GPU com CUDA (opcional, mas recomendado).

---

## ğŸš€ Treinamento

1. **PrÃ©-processamento:** As imagens brutas foram organizadas e renomeadas via `preprocessing.py`.

2. **AnotaÃ§Ã£o:** Um subconjunto das imagens de treino foi anotado com a ferramenta [VGG VIA](https://www.robots.ox.ac.uk/~vgg/software/via/), e as mÃ¡scaras foram geradas com `train_masks.py` e `val_masks.py`.

3. **DivisÃ£o dos dados:** O conjunto foi dividido em treino (70%), validaÃ§Ã£o (15%) e teste (15%) com controle de semente. Apenas imagens originais estÃ£o presentes no conjunto de teste.

4. **Treinamento:** Execute o seguinte comando para treinar o modelo:

```bash
python train.py
```

Durante o treinamento:
- As prediÃ§Ãµes sobre o conjunto de validaÃ§Ã£o sÃ£o salvas em `val_preds_vis/`.
- As curvas de desempenho (`loss_curve.png` e `dice_curve.png`) sÃ£o geradas.

---

## ğŸ“Š Principais Resultados

ApÃ³s 20 Ã©pocas de treinamento com `UNetCustom`:

| MÃ©trica    | Treino   | ValidaÃ§Ã£o |
|------------|----------|-----------|
| Dice       | ~0.41    | ~0.39     |
| IoU        | ~0.28    | ~0.25     |
| Precision  | ~0.54    | ~0.48     |
| Recall     | ~0.34    | ~0.32     |

> AtÃ© o momento, as mÃ¡scaras geradas destacam regiÃµes da face, sendo necessÃ¡rio aprimorar o projeto para as regiÃµes de espinhas. As mÃ©tricas obtidas indicam que o modelo Ã© capaz de identificar algumas regiÃµes com espinhas, mas ainda apresenta desempenho limitado.
> O Dice (~0.39) e o IoU (~0.25) refletem a dificuldade de segmentar corretamente objetos pequenos e pouco representados. O modelo demonstrou boa precisÃ£o (~0.48), evitando falsos positivos, porÃ©m com baixo recall (~0.32), o que sugere que muitas espinhas reais nÃ£o foram detectadas.
> Esses resultados reforÃ§am a necessidade de ampliar a base anotada, refinar o modelo e explorar estratÃ©gias especÃ­ficas para objetos pequenos.

---

## ğŸ§  EstratÃ©gia de AnotaÃ§Ã£o e DivisÃ£o

- **AnotaÃ§Ã£o:** Como o dataset original nÃ£o possuÃ­a labels, foi feita anotaÃ§Ã£o manual de um subconjunto de imagens usando a ferramenta VIA (VGG Image Annotator). As mÃ¡scaras geradas sÃ£o binÃ¡rias, com **255 nas regiÃµes com espinhas**.

- **DivisÃ£o:** A separaÃ§Ã£o entre treino, validaÃ§Ã£o e teste foi baseada em uma distribuiÃ§Ã£o 70/15/15 sobre **todas as imagens disponÃ­veis**, garantindo que **nenhuma imagem de teste contenha dados aumentados**.

> Imagens anotadas manualmente foram usadas apenas em `train_sub` e `val_sub`, para garantir qualidade das mÃ©tricas.

---
## âœ¨ Futuro

- Aplicar pÃ³s-processamento para reduzir falsos positivos  
- Avaliar com mÃ©tricas adicionais como mAP  
- Anotar mais imagens para refinar o treinamento  
- Aprimorar a rede U-Net para suavizar as perdas das pequenas regiÃµes, com maior atenÃ§Ã£o para as ocorrÃªncias de acne
